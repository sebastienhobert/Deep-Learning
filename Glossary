Activation Function = it decides whether a neuron should be activated or not based on its input to the network

Adam Optimizer = (Adaptive moment estimation) it adjusts the learning rate for each individual parameter within a model rather than using a single global learning rate

Batch Normalization = it helps in stabilizing the training process. It enables higher learning rates and faster convergence

Backpropagation = the goal is to reduce the difference between the model's predicted output and the actual output by adjusting the weights and biases in the network

Classification = a machine learning model used for distinguishing among two or more output categories

Convolutional Neural Network (CNN) = network architecture used for image recognition and processing (due to its ability to recognize patterns in images)

Cross-Entropy = loss function to measure the difference between the predicted probability distribution and the true distribution

Dense Layer = a linear operation in which every input is connected to every output by a weight

Flattening = converting 2d image to 1d vector

Loss Function = it measures the difference between the prediction and the actual output

Optimizer = helps to minimize the loss function

Overfitting = when a model gets trained with so much data, it starts learning from the noise and inaccurate data entries

ReLU = an activation function that allows a model to solve nonlinear problems

Softmax = a function that provides probabilities for each possible output class

Stochastic = random probability distribution

Tensor = a tensor is a multidimensional array that represents the data in a machine learning model